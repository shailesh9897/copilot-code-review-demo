name: AI Code Review  # Shown in Actions tab

on:
  pull_request:                      # Run on PRs
    types: [opened, synchronize, reopened]

jobs:
  review:
    runs-on: ubuntu-latest

    # Minimal perms to read code and write PR comments
    permissions:
      pull-requests: write
      contents: read

    # === Toggle here if you want OpenAI instead of Ollama ===
    # USE_OLLAMA: 'true' -> use local model via Ollama on the runner
    # USE_OLLAMA: 'false' -> use OpenAI (needs OPENAI_API_KEY secret)
    env:
      USE_OLLAMA: 'true'
      OLLAMA_MODEL: 'llama3.1'                 # change to mistral, qwen2.5, etc.
      OPENAI_MODEL: 'gpt-4o-mini'              # used only when USE_OLLAMA!='true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0                       # full history so we can diff any two SHAs

      - name: Install Python deps
        run: |
          python3 -m pip install --upgrade pip
          pip install requests

      # --- Only runs when using Ollama ---
      - name: Install & start Ollama
        if: env.USE_OLLAMA == 'true'
        run: |
          set -e
          curl -fsSL https://ollama.com/install.sh | sh
          nohup ollama serve > /tmp/ollama.log 2>&1 &
          # Wait for API to come up
          for i in {1..30}; do
            curl -s http://127.0.0.1:11434/api/tags >/dev/null && break
            sleep 1
          done
          echo "Pulling model: ${OLLAMA_MODEL}"
          ollama pull "${OLLAMA_MODEL}"

      - name: Generate and post AI review
        env:
          # GitHub context
          GITHUB_TOKEN:    ${{ secrets.GITHUB_TOKEN }}
          REPO:            ${{ github.repository }}
          PR_NUMBER:       ${{ github.event.pull_request.number }}
          BASE_SHA:        ${{ github.event.pull_request.base.sha }}
          HEAD_SHA:        ${{ github.event.pull_request.head.sha }}

          # Model selection
          USE_OLLAMA:      ${{ env.USE_OLLAMA }}
          OLLAMA_MODEL:    ${{ env.OLLAMA_MODEL }}
          OPENAI_MODEL:    ${{ env.OPENAI_MODEL }}

          # Optional OpenAI secret (used only if USE_OLLAMA!='true')
          OPENAI_API_KEY:  ${{ secrets.OPENAI_API_KEY }}
        run: |
          set -e
          echo "Base: ${BASE_SHA}"
          echo "Head: ${HEAD_SHA}"
          git fetch --no-tags --prune --depth=1 origin "${BASE_SHA}" "${HEAD_SHA}"
          git diff --unified=0 "${BASE_SHA}" "${HEAD_SHA}" > diff.txt || true
          echo "Diff bytes: $(wc -c < diff.txt)"

          python3 - <<'PY'
          import os, json, requests, sys, pathlib, time

          repo = os.environ["REPO"]
          pr   = os.environ["PR_NUMBER"]
          gh_headers = {
              "Authorization": f"Bearer {os.environ['GITHUB_TOKEN']}",
              "Accept": "application/vnd.github+json"
          }
          def comment(body: str):
              url = f"https://api.github.com/repos/{repo}/issues/{pr}/comments"
              r = requests.post(url, headers=gh_headers, json={"body": body})
              print("Comment status:", r.status_code, r.text[:200])

          # Ensure we actually have something to review
          diff_path = pathlib.Path("diff.txt")
          if not diff_path.exists() or diff_path.stat().st_size == 0:
              comment("ðŸ¤– **AI Code Review Bot:** No diff content detected for this PR.")
              sys.exit(0)

          diff = diff_path.read_text(encoding="utf-8", errors="ignore")[:60000]

          # Review prompt (Java/Spring focused)
          prompt = f"""You are a senior Java/Spring reviewer. Review this unified git diff and provide concise bullet points.
          Prioritize:
          - Null-safety (Optional.get, potential NPEs)
          - SQL & resource handling (PreparedStatement, try-with-resources)
          - Logging/PII masking
          - Performance (boxing, inefficient loops)
          - General Spring/Java best practices
          If no issues, say 'No issues found.'
          Diff:
          {diff}
          """

          use_ollama = os.environ.get("USE_OLLAMA","").lower() == "true"
          review_text = None

          if use_ollama:
              # -------- Ollama local inference --------
              model = os.environ.get("OLLAMA_MODEL","llama3.1")
              body = {
                "model": model,
                "messages": [{"role":"user","content": prompt}],
                "stream": False
              }
              try:
                  r = requests.post("http://127.0.0.1:11434/api/chat",
                                    data=json.dumps(body),
                                    headers={"Content-Type":"application/json"},
                                    timeout=180)
                  r.raise_for_status()
                  review_text = r.json().get("message",{}).get("content","").strip()
              except Exception as e:
                  review_text = f"âš ï¸ Ollama error: {e}"
          else:
              # -------- OpenAI fallback --------
              key = os.environ.get("OPENAI_API_KEY","")
              if not key:
                  comment("â— **AI Code Review Bot:** Missing `OPENAI_API_KEY` and USE_OLLAMA!=true.")
                  sys.exit(0)
              body = {
                "model": os.environ.get("OPENAI_MODEL","gpt-4o-mini"),
                "messages": [{"role":"user","content": prompt}],
                "temperature": 0.2
              }
              # Simple retry loop for transient errors
              last = None
              for attempt in range(5):
                  try:
                      r = requests.post(
                          "https://api.openai.com/v1/chat/completions",
                          headers={"Authorization": f"Bearer {key}",
                                   "Content-Type":"application/json"},
                          data=json.dumps(body),
                          timeout=90
                      )
                      if r.status_code in (429,500,502,503,504):
                          time.sleep([2,4,8,16,30][attempt])
                          last = r
                          continue
                      r.raise_for_status()
                      review_text = r.json()["choices"][0]["message"]["content"].strip()
                      break
                  except Exception as e:
                      last = e
              if review_text is None:
                  comment(f"âš ï¸ **AI Code Review Bot:** OpenAI call failed. {last}")
                  sys.exit(0)

          if not review_text:
              review_text = "No issues found."

          comment(f"ðŸ¤– **AI Code Review Bot**\n\n{review_text}")
          PY
